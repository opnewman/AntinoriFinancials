from fastapi import FastAPI, UploadFile, File, Depends, HTTPException, Query, Response, BackgroundTasks
from sqlalchemy.orm import Session
from backend.database import get_db, init_db
from backend.src.controllers.report_controller import (
    upload_data_dump,
    upload_ownership_tree,
    upload_security_risk_stats,
    generate_portfolio_report,
    get_ownership_tree,
    get_chart_allocations,
    get_chart_performance,
    get_chart_liquidity
)
from backend.egnyte_api import download_file
from apscheduler.schedulers.asyncio import AsyncIOScheduler
from apscheduler.triggers.cron import CronTrigger
from datetime import datetime
import structlog
import os
from dotenv import load_dotenv
import json

# Load environment variables
load_dotenv()

# Initialize logging
logger = structlog.get_logger()

# Initialize FastAPI app
app = FastAPI(title="ANTINORI Backend", description="Financial services backend for multi-family office")

# Initialize the scheduler
scheduler = AsyncIOScheduler(timezone="US/Eastern")

# Egnyte configuration
ACCESS_TOKEN = os.getenv("EGNYTE_ACCESS_TOKEN")
FILE_PATH = r"/Shared/Internal Documents/Proficio Capital Partners/Asset Allocation/Portfolio Management/New Portfolio Sheets/Security Risk Stats.xlsx"

# Initialize database and scheduler on startup
@app.on_event("startup")
async def on_startup():
    try:
        init_db()
        logger.info("Database initialized")
    except Exception as e:
        logger.error("Failed to initialize database", error=str(e))
        raise

    # Start the scheduler
    scheduler.start()
    logger.info("Scheduler started")

    # Schedule the risk stats download and upload at 8 AM EST
    scheduler.add_job(
        run_risk_stats_download_and_upload,
        CronTrigger(hour=8, minute=0, timezone="US/Eastern"),
        id="risk_stats_upload",
        replace_existing=True
    )
    logger.info("Scheduled risk stats download and upload at 8 AM EST")

@app.on_event("shutdown")
async def shutdown_event():
    # Shut down the scheduler
    scheduler.shutdown()
    logger.info("Scheduler shut down")

# Function to run the risk stats download and upload
async def run_risk_stats_download_and_upload():
    try:
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"risk_stats_{timestamp}.xlsx"
        file_path = os.path.join("risk_stats_data", filename)

        # Ensure the directory exists
        os.makedirs("risk_stats_data", exist_ok=True)

        # Download the file from Egnyte
        await download_file(ACCESS_TOKEN, FILE_PATH, file_path)
        logger.info(f"Downloaded risk stats file: {filename}")

        # Process the file
        with open(file_path, "rb") as f:
            upload_file = UploadFile(file=f, filename=filename)
            db: Session = next(get_db())
            await upload_security_risk_stats(upload_file, db)
        logger.info(f"Processed risk stats file: {filename}")
    except Exception as e:
        logger.error(f"Error during scheduled risk stats download and upload: {str(e)}")

# API Endpoints

# Endpoint to upload data dump
@app.post("/upload/data_dump")
async def upload_data_dump_endpoint(
    file: UploadFile = File(...),
    report_date: str = Query(..., regex=r"^\d{4}-\d{2}-\d{2}$"),
    db: Session = Depends(get_db)
):
    """
    Upload and process data_dump.xlsx for a specific date.
    """
    try:
        if not file.filename.endswith(".xlsx"):
            raise HTTPException(status_code=400, detail="Invalid file format. Expected .xlsx")
        logger.info(f"Processing upload: {file.filename} for date {report_date}")
        await upload_data_dump(file, report_date, db)
        return {"message": f"Uploaded data_dump.xlsx for date {report_date}"}
    except Exception as e:
        logger.error(f"Error uploading data_dump: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Error processing file: {str(e)}")

# Endpoint to upload ownership tree
@app.post("/upload/ownership_tree")
async def upload_ownership_tree_endpoint(
    file: UploadFile = File(...),
    db: Session = Depends(get_db)
):
    """
    Upload and process ownership.xlsx, replacing existing data.
    """
    try:
        if not file.filename.endswith(".xlsx"):
            raise HTTPException(status_code=400, detail="Invalid file format. Expected .xlsx")
        logger.info(f"Processing upload: {file.filename}")
        await upload_ownership_tree(file, db)
        return {"message": "Uploaded ownership.xlsx"}
    except Exception as e:
        logger.error(f"Error uploading ownership_tree: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Error processing file: {str(e)}")

# Endpoint to upload security risk stats
@app.post("/upload/security_risk_stats")
async def upload_security_risk_stats_endpoint(
    file: UploadFile = File(...),
    db: Session = Depends(get_db)
):
    """
    Upload and process risk_stats.xlsx with three tabs.
    """
    try:
        if not file.filename.endswith(".xlsx"):
            raise HTTPException(status_code=400, detail="Invalid file format. Expected .xlsx")
        logger.info(f"Processing upload: {file.filename}")
        await upload_security_risk_stats(file, db)
        return {"message": "Uploaded risk_stats.xlsx"}
    except Exception as e:
        logger.error(f"Error uploading security_risk_stats: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Error processing file: {str(e)}")

# Endpoint to generate portfolio report
@app.get("/generate_portfolio_report")
def generate_portfolio_report_endpoint(
    date: str = Query(..., regex=r"^\d{4}-\d{2}-\d{2}$"),
    level: str = Query("portfolio", enum=["client", "group", "portfolio", "account", "custom"]),
    filters: str = Query(None),  # JSON string, e.g., '{"portfolios": ["Portfolio1"]}'
    db: Session = Depends(get_db)
):
    """
    Generate a portfolio report for a specific date at the specified level.
    Args:
        date: The date for the report (YYYY-MM-DD).
        level: The level ('client', 'group', 'portfolio', 'account', 'custom').
        filters: Optional JSON string specifying entities to include (e.g., '{"portfolios": ["Portfolio1"]}').
    """
    try:
        filter_dict = json.loads(filters) if filters else None
        logger.info(f"Generating portfolio report for date {date} at level {level} with filters {filter_dict}")
        report = generate_portfolio_report(date, db, level, filter_dict)
        return report
    except Exception as e:
        logger.error(f"Error generating portfolio report: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Error generating report: {str(e)}")

# Endpoint to get allocation chart data
@app.get("/portfolio_report/chart/allocations")
def get_chart_allocations_endpoint(
    date: str = Query(..., regex=r"^\d{4}-\d{2}-\d{2}$"),
    level: str = Query("portfolio", enum=["client", "group", "portfolio", "account", "custom"]),
    filters: str = Query(None),
    db: Session = Depends(get_db)
):
    """
    Get allocation data for chart visualization.
    """
    try:
        filter_dict = json.loads(filters) if filters else None
        logger.info(f"Generating allocation chart data for date {date} at level {level} with filters {filter_dict}")
        chart_data = get_chart_allocations(date, db, level, filter_dict)
        return chart_data
    except Exception as e:
        logger.error(f"Error generating allocation chart data: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Error generating chart data: {str(e)}")

# Endpoint to get performance chart data
@app.get("/portfolio_report/chart/performance")
def get_chart_performance_endpoint(
    date: str = Query(..., regex=r"^\d{4}-\d{2}-\d{2}$"),
    level: str = Query("portfolio", enum=["client", "group", "portfolio", "account", "custom"]),
    filters: str = Query(None),
    db: Session = Depends(get_db)
):
    """
    Get performance data for chart visualization.
    """
    try:
        filter_dict = json.loads(filters) if filters else None
        logger.info(f"Generating performance chart data for date {date} at level {level} with filters {filter_dict}")
        chart_data = get_chart_performance(date, db, level, filter_dict)
        return chart_data
    except Exception as e:
        logger.error(f"Error generating performance chart data: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Error generating chart data: {str(e)}")

# Endpoint to get liquidity chart data
@app.get("/portfolio_report/chart/liquidity")
def get_chart_liquidity_endpoint(
    date: str = Query(..., regex=r"^\d{4}-\d{2}-\d{2}$"),
    level: str = Query("portfolio", enum=["client", "group", "portfolio", "account", "custom"]),
    filters: str = Query(None),
    db: Session = Depends(get_db)
):
    """
    Get liquidity data for chart visualization.
    """
    try:
        filter_dict = json.loads(filters) if filters else None
        logger.info(f"Generating liquidity chart data for date {date} at level {level} with filters {filter_dict}")
        chart_data = get_chart_liquidity(date, db, level, filter_dict)
        return chart_data
    except Exception as e:
        logger.error(f"Error generating liquidity chart data: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Error generating chart data: {str(e)}")

# Endpoint to get ownership tree
@app.get("/ownership_tree")
def get_ownership_tree_endpoint(db: Session = Depends(get_db)):
    """
    Retrieve the ownership hierarchy as a JSON tree.
    """
    try:
        logger.info("Retrieving ownership tree")
        tree = get_ownership_tree(db)
        return tree
    except Exception as e:
        logger.error(f"Error retrieving ownership tree: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Error retrieving tree: {str(e)}")

# Endpoint to download and process risk stats from Egnyte
@app.post("/api/download-risk-stats")
async def manual_download(background_tasks: BackgroundTasks, db: Session = Depends(get_db)):
    """
    Trigger the download of the risk stats Excel file from Egnyte and process it into the database.
    """
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    filename = f"risk_stats_{timestamp}.xlsx"
    file_path = os.path.join("risk_stats_data", filename)
    
    # Ensure the directory exists
    os.makedirs("risk_stats_data", exist_ok=True)

    # Download the file in the background
    background_tasks.add_task(download_file, ACCESS_TOKEN, FILE_PATH, file_path)

    # Process the file after download
    async def process_file():
        try:
            with open(file_path, "rb") as f:
                upload_file = UploadFile(file=f, filename=filename)
                await upload_security_risk_stats(upload_file, db)
            logger.info(f"Processed risk stats file: {filename}")
        except Exception as e:
            logger.error(f"Error processing risk stats file {filename}: {str(e)}")

    background_tasks.add_task(process_file)
    return {"message": f"Download and processing of {filename} started in the background"}

# Root endpoint
@app.get("/")
def read_root():
    return {"message": "Welcome to ANTINORI Backend"}

# Favicon endpoint to avoid 404 errors
@app.get("/favicon.ico")
def get_favicon():
    # For now, return an empty response to avoid 404
    # You can replace this with an actual favicon file later
    return Response(content=b"", media_type="image/x-icon")